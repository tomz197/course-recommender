{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import json\n",
    "\n",
    "from scripts.helpers import load_courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21485"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "courses = load_courses('./data/generated/')[0]\n",
    "len(courses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features (terms): 5000\n",
      "TF-IDF matrix shape: (21485, 5000)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Extract text data from courses for TF-IDF processing\n",
    "# We'll combine relevant text fields from each course to create a corpus\n",
    "corpus = []\n",
    "course_codes = []\n",
    "\n",
    "for course in courses:\n",
    "    # Combine relevant text fields into a single document\n",
    "    # document = f\"{course['NAME']} {course['SYLLABUS']} {course['OBJECTIVES']} {course['LEARNING_OUTCOMES']} {course['DESCRIPTION']}\"\n",
    "    document = json.dumps(course, ensure_ascii=False)\n",
    "\n",
    "    # Add keywords if available\n",
    "    if 'KEYWORDS' in course and course['KEYWORDS']:\n",
    "        document += \" \" + \" \".join(course['KEYWORDS'])\n",
    "\n",
    "    corpus.append(document)\n",
    "    course_codes.append(course['CODE'])\n",
    "\n",
    "# Initialize and fit the TF-IDF vectorizer\n",
    "# max_features limits the vocabulary size to the most important terms\n",
    "# stop_words removes common English words that don't carry much meaning\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_features=5000,\n",
    "    stop_words='english',\n",
    "    lowercase=True,\n",
    "    norm='l2',\n",
    "    use_idf=True,\n",
    "    smooth_idf=True,\n",
    "    sublinear_tf=True  # Apply sublinear tf scaling (1 + log(tf))\n",
    ")\n",
    "\n",
    "# Transform the corpus into TF-IDF features\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Get feature names (terms)\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "print(f\"Number of features (terms): {len(feature_names)}\")\n",
    "print(f\"TF-IDF matrix shape: {tfidf_matrix.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top terms for course bk4001 - Methodology:\n",
      "  renata: 0.1705\n",
      "  citation: 0.1677\n",
      "  hendl: 0.1526\n",
      "  statistical: 0.1363\n",
      "  kvalitativní: 0.1357\n"
     ]
    }
   ],
   "source": [
    "# Example: Get the top 5 terms for the first course\n",
    "def get_top_terms(doc_idx, top_n=5):\n",
    "    feature_index = tfidf_matrix[doc_idx].nonzero()[1]\n",
    "    tfidf_scores = zip(feature_index, [tfidf_matrix[doc_idx, x] for x in feature_index])\n",
    "    sorted_scores = sorted(tfidf_scores, key=lambda x: x[1], reverse=True)\n",
    "    return [(feature_names[idx], score) for idx, score in sorted_scores[:top_n]]\n",
    "\n",
    "# Display top terms for the first course\n",
    "if len(courses) > 0:\n",
    "    print(f\"\\nTop terms for course {course_codes[0]} - {courses[0]['NAME']}:\")\n",
    "    for term, score in get_top_terms(0):\n",
    "        print(f\"  {term}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CODE': 'IB111', 'FACULTY': 'FI', 'NAME': 'Foundations of Programming', 'LANGUAGE': 'čeština', 'SEMESTER': 'podzim 2024', 'CREDITS': '5', 'DEPARTMENT': 'KPSK', 'TEACHERS': 'Beneš, N. - Bartek, F. - Bednařík, K. - Borošová, K. - Brdečko, V. - Bukor, O. - Burget, J. - Čepela, S. - Focko, M. - Foltýnek, T. - Glosner, R. - Jedelský, J. - Juračková, N. - Kasprzaková, I. - Lukačovič, B. - Marek, T. - Melkovič, D. - Pastva, S. - Patlevič, M. - Rakšány, P. - Ročkai, P. - Ručka, L. - Sedlák, E. - Stančík, S. - Šutor, D. - Trnavský, P. - Tuček, M. - Tvarožek, M. - Uhlík, V. - Vojnar, T. - Weinberger, F. - Winklerová, A. - Wolek, J. - Záborský, L. - Zatloukal, J. - Žbánek, V. - Balák, T. - Baník, R. - Barna, M. - Béreš, J. - Biačko, P. - Borský, J. - Bukáček, M. - Čech, R. - Čermák, K. - Černá, I. - Davidová, N. - Drkoš, T. - Dvořák, R. - Ergang, M. - Fedorko, F. - Frejlach, J. - Glos, J. - Hadar, A. - Halabala, J. - Halamka, M. - Hejčl, P. - Horák, J. - Jarošová, J. - Judiny, J. - Kamenov, D. - Kapko, J. - Kecskésová, M. - Kinská, T. - Klapetek, V. - Klostermann, T. - Korž, M. - Kotúček, P. - Krchňák, T. - Kubica, P. - Kubík, A. - Lacko, R. - Lopatka, A. - Ludvig, L. - Mackovík, M. - Marcinech, M. - Martišová, S. - Matuška, J. - Metelka, O. - Nadzam, M. - Novák, P. - Ondulič, M. - Pavelka, A. - Pavlovič, F. - Piatková, B. - Pittner, L. - Rábek, M. - Rádl, J. - Rohlínek, T. - Řechtáčková, A. - Sabo, J. - Simandl, J. - Sviatková, S. - Szalona, G. - Tejbus, A. - Tomíček, T. - Vajda, P. - Valalský, A. - Valková, D. - Zemančík, J. - Zemanová, V. - Žižka, J.', 'COMPLETION': 'zk', 'PREREQUISITES': 'předp. ! IB113 && ! NOW ( IB113 )', 'FIELDS_OF_STUDY': 'DL, IN, PVA, BCS, INFMAJ', 'TYPE_OF_STUDY': 'bakalářský, magisterský navazující', 'LECTURES_SEMINARS_HOMEWORK': '2/2/2', 'SYLLABUS': 'The course shows the basic elements of imperative programming and algorithmic thinking using the high-level programming language Python as an example.\\n    Basic notions of imperative programming languages: variables and their semantics, expressions and statements, branching, cycles; subroutines (functions), passing parameters (calling functions), pure functions, predicates.\\n    Numerical computation, basic data types, using the random generator.\\n    Data structures, ADT, lists, strings, multidimensional arrays, sets, dictionaries, the basic of using objects to create user-defined data structures.\\n    The basics of testing and debugging, preconditions and postconditions, type annotation.\\n    Examples of basic algorithms: greatest common divisor, prime numbers, sorting algorithms, searching.\\n    The efficiency of algorithms, the basics of complexity, the complexity of basic data structures operations.\\n    Recursion and its specifics in the imperative paradigm, tail recursion; using recursion to work with tree data structures and to solve constraint satisfaction problems (the basics of the backtracking technique).\\n    Interaction with the environment (I/O), turtle graphics, bitmap graphics, text processing.\\n    Program design, programming styles and conventions, readability and maintainability of code, documentation and comments.', 'OBJECTIVES': 'The course is an introduction to programming and algorithmic style of thinking.', 'TEXT_PREREQUISITS': '', 'ASSESMENT_METHODS': 'Assesment consists of 3 parts: homeworks, mid-term and final programming tests, final written test.', 'TEACHING_METHODS': 'lectures, programming seminars, homeworks (programming)', 'TEACHER_INFO': '', 'LEARNING_OUTCOMES': 'At the end of the course students should be able to: understand and apply basic constructs of programming languages (e.g., conditions, loops, functions, basic data types); write and debug a program in Python; use basic data types and structures (strings, lists, dictionaries); describe several basic algorithms; describe main conventions and recommended programming style.', 'LITERATURE': '\\n        PELÁNEK, Radek. Programátorská cvičebnice: algoritmy v příkladech. Brno: Computer Press, 2012, 175 s. ISBN 978-80-251-3751-2. info\\n        GUZDIAL, Mark a Barbara ERICSON. Introduction to computing & programming in Python : a multimedia approach. 2nd ed. Upper Saddle River [N.J.]: Prentice Hall, 2010, xxiii, 401. ISBN 9780136060239. info\\n        ZELLE, John M. Python programming : an introduction to computer science. Wilsonville: Franklin, Beedle &Associates, 2004, xiv, 514. ISBN 1887902996. info \\n    ', 'STUDENTS_ENROLLED': '786', 'STUDENTS_PASSED': '332', 'AVERAGE_GRADE': '3.05', 'FOLLOWUP_COURSES': 'IB002,PB111,PV248', 'KEYWORDS': ['programming', 'python', 'imperative programming', 'algorithmic thinking', 'data structures', 'debugging', 'program design', 'algorithms', 'code', 'functions', 'loops', 'basic data types', 'testing', 'recursion', 'i/o'], 'DESCRIPTION': \"Want to learn programming from the ground up? This course introduces imperative programming and algorithmic thinking using Python. You'll learn basic data structures, debugging, and program design. Get hands-on experience with programming seminars and homework assignments, and learn to write clean, maintainable code.\", 'RATINGS': {'theoretical_vs_practical': '6', 'usefulness': '8', 'interest': '7', 'stem_vs_humanities': '2', 'abstract_vs_specific': '7', 'difficulty': '5', 'multidisciplinary': '3', 'project_based': '7', 'creative': '5'}}\n"
     ]
    }
   ],
   "source": [
    "code = \"IB111\"\n",
    "\n",
    "for course in courses:\n",
    "    if course['CODE'] == code:\n",
    "        print(course)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 15 terms for course PB111 - Principles of low-level programming:\n",
      "  programming: 0.2232\n",
      "  memory: 0.2184\n",
      "  trees: 0.1974\n",
      "  allocation: 0.1898\n",
      "  computational: 0.1805\n",
      "  tables: 0.1670\n",
      "  dynamic: 0.1635\n",
      "  algorithms: 0.1588\n",
      "  machine: 0.1529\n",
      "  low: 0.1501\n",
      "  search: 0.1317\n",
      "  blocks: 0.1263\n",
      "  variable: 0.1243\n",
      "  block: 0.1224\n",
      "  linked: 0.1203\n"
     ]
    }
   ],
   "source": [
    "# Find the index of the course with code 'IB111'\n",
    "ib111_idx = None\n",
    "for i, code in enumerate(course_codes):\n",
    "    if code == 'PB111':\n",
    "        ib111_idx = i\n",
    "        break\n",
    "\n",
    "# Display top 15 terms for IB111 if found\n",
    "if ib111_idx is not None:\n",
    "    course_name = courses[ib111_idx]['NAME']\n",
    "    print(f\"\\nTop 15 terms for course {course_codes[ib111_idx]} - {course_name}:\")\n",
    "    for term, score in get_top_terms(ib111_idx, top_n=15):\n",
    "        print(f\"  {term}: {score:.4f}\")\n",
    "else:\n",
    "    print(\"\\nCourse with code 'IB111' not found in the dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting top keywords for each course...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21485/21485 [00:54<00:00, 394.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top keywords saved to course_top_keywords.json\n",
      "\n",
      "Sample of extracted keywords:\n",
      "\n",
      "Course bk4001:\n",
      "  renata: 0.1705\n",
      "  citation: 0.1677\n",
      "  hendl: 0.1526\n",
      "  statistical: 0.1363\n",
      "  kvalitativní: 0.1357\n",
      "  ...\n",
      "\n",
      "Course bk4003:\n",
      "  sports: 0.2199\n",
      "  spelling: 0.1831\n",
      "  anatomy: 0.1688\n",
      "  cefr: 0.1614\n",
      "  sport: 0.1569\n",
      "  ...\n",
      "\n",
      "Course bk4005:\n",
      "  pedagogy: 0.1748\n",
      "  socialization: 0.1746\n",
      "  průcha: 0.1691\n",
      "  pedagogical: 0.1627\n",
      "  youth: 0.1493\n",
      "  ...\n"
     ]
    }
   ],
   "source": [
    "# Extract top 15 keywords for each course and store in a JSON file\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Create a dictionary to store course codes and their top keywords\n",
    "course_keywords = {}\n",
    "\n",
    "# Process each course\n",
    "print(\"Extracting top keywords for each course...\")\n",
    "for idx, code in enumerate(tqdm(course_codes)):\n",
    "    # Get the top 15 terms for this course\n",
    "    top_terms = get_top_terms(idx, top_n=15)\n",
    "\n",
    "    # Store as a dictionary with term and score\n",
    "    course_keywords[code] = [{\"term\": term, \"score\": float(score)} for term, score in top_terms]\n",
    "\n",
    "# Save to JSON file\n",
    "output_file = \"course_top_keywords.json\"\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(course_keywords, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"Top keywords saved to {output_file}\")\n",
    "\n",
    "# Display sample of the data (first 3 courses)\n",
    "print(\"\\nSample of extracted keywords:\")\n",
    "sample_count = min(3, len(course_codes))\n",
    "for i, code in enumerate(list(course_keywords.keys())[:sample_count]):\n",
    "    print(f\"\\nCourse {code}:\")\n",
    "    for item in course_keywords[code][:5]:  # Show only top 5 for the sample\n",
    "        print(f\"  {item['term']}: {item['score']:.4f}\")\n",
    "    if len(course_keywords[code]) > 5:\n",
    "        print(\"  ...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing course similarity function:\n",
      "\n",
      "Similarity matrix for sample courses:\n",
      "Course Codes: ['IB111', 'IB031', 'PB161', 'IB002', 'IV109']\n",
      "--------------------------------------------------\n",
      "IB111: 0.0732, 0.0000, 0.0096, 0.0314, 0.0047\n",
      "IB031: 0.0000, 0.0697, 0.0000, 0.0073, 0.0104\n",
      "PB161: 0.0096, 0.0000, 0.0688, 0.0046, 0.0000\n",
      "IB002: 0.0314, 0.0073, 0.0046, 0.0709, 0.0058\n",
      "IV109: 0.0047, 0.0104, 0.0000, 0.0058, 0.0707\n",
      "\n",
      "Most similar courses to IA161 (Natural Language Processing in Practice):\n",
      "  PA153 - Natural Language Processing: 0.0311\n",
      "  F4500 - Python for physicists: 0.0254\n",
      "  PLIN013 - Proseminar, Pt. I: 0.0250\n",
      "  Z8154 - Programming in geoinformatics: 0.0245\n",
      "  PA154 - Language Modeling: 0.0243\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate similarity between courses based on shared keywords\n",
    "def calculate_course_similarity(course1_code, course2_code, course_keywords, weight_by_score=True):\n",
    "    if course1_code not in course_keywords or course2_code not in course_keywords:\n",
    "        return 0.0\n",
    "\n",
    "    keywords1 = {item[\"term\"]: item[\"score\"] for item in course_keywords[course1_code]}\n",
    "    keywords2 = {item[\"term\"]: item[\"score\"] for item in course_keywords[course2_code]}\n",
    "\n",
    "    shared_keywords = set(keywords1.keys()) & set(keywords2.keys())\n",
    "\n",
    "    if not shared_keywords:\n",
    "        return 0.0\n",
    "\n",
    "    if weight_by_score:\n",
    "        similarity = sum(keywords1[term] * keywords2[term] for term in shared_keywords)\n",
    "        total_possible = sum(keywords1.values()) * sum(keywords2.values())\n",
    "        if total_possible > 0:\n",
    "            similarity = similarity / total_possible\n",
    "    else:\n",
    "        similarity = len(shared_keywords) / len(set(keywords1.keys()) | set(keywords2.keys()))\n",
    "\n",
    "    return similarity\n",
    "\n",
    "print(\"\\nTesting course similarity function:\")\n",
    "\n",
    "test_courses = ['IB111', 'IB031', 'PB161', 'IB002', 'IV109']\n",
    "\n",
    "print(\"\\nSimilarity matrix for sample courses:\")\n",
    "print(\"Course Codes:\", test_courses)\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Create a similarity matrix for the test courses\n",
    "for i, course1 in enumerate(test_courses):\n",
    "    similarities = []\n",
    "    for j, course2 in enumerate(test_courses):\n",
    "        sim = calculate_course_similarity(course1, course2, course_keywords)\n",
    "        similarities.append(f\"{sim:.4f}\")\n",
    "    print(f\"{course1}: {', '.join(similarities)}\")\n",
    "\n",
    "# Find the most similar course to a specific course\n",
    "def find_most_similar_courses(course_code, course_keywords, top_n=5):\n",
    "    if course_code not in course_keywords:\n",
    "        return []\n",
    "\n",
    "    similarities = []\n",
    "    for other_code in course_keywords:\n",
    "        if other_code != course_code:\n",
    "            sim = calculate_course_similarity(course_code, other_code, course_keywords)\n",
    "            similarities.append((other_code, sim))\n",
    "\n",
    "    # Sort by similarity score in descending order\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    return similarities[:top_n]\n",
    "\n",
    "# Test finding similar courses for a specific course\n",
    "if 'IA161' in course_keywords:  # Natural Language Processing in Practice\n",
    "    print(\"\\nMost similar courses to IA161 (Natural Language Processing in Practice):\")\n",
    "    similar_courses = find_most_similar_courses('IA161', course_keywords)\n",
    "    for code, sim in similar_courses:\n",
    "        # Find the course name if available\n",
    "        course_name = \"\"\n",
    "        for idx, c_code in enumerate(course_codes):\n",
    "            if c_code == code:\n",
    "                course_name = courses[idx]['NAME']\n",
    "                break\n",
    "        print(f\"  {code} - {course_name}: {sim:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lmi-starterpack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
