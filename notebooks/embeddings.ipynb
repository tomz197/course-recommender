{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "import sys\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, os.pardir))\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from google import genai\n",
    "from scripts.embedding_helpers import similarity\n",
    "\n",
    "client = genai.Client(api_key=os.getenv(\"GEMINI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21106\n"
     ]
    }
   ],
   "source": [
    "from scripts.helpers import get_only_generated_info, load_courses\n",
    "\n",
    "# courses, ctoi = load_courses(\"../data/formatted/fi.json\")\n",
    "# courses2, ctoi2 = load_courses(\"../data/formatted/přf.json\")\n",
    "\n",
    "# courses = courses + courses2\n",
    "\n",
    "# for key, value in ctoi2.items():\n",
    "#     ctoi2[key] = value + len(ctoi)\n",
    "\n",
    "# ctoi.update(ctoi2)\n",
    "\n",
    "courses, ctoi = load_courses(\"../data/formatted\")\n",
    "\n",
    "print(len(courses))\n",
    "# courses_generated_info = get_only_generated_info(courses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CODE': ' LSP_TA_S ', 'FACULTY': ' CST ', 'NAME': ' LAP and LSP teacher assistant - Spanish ', 'LANGUAGE': ' španělština ', 'SEMESTER': ' podzim 2024 ', 'CREDITS': ' 2 ', 'DEPARTMENT': ' ', 'TEACHERS': ' Alchazidu, A. - De Azevedo Camacho, V. - Žváčková, J. - Holasová, M. ', 'COMPLETION': ' z ', 'PREREQUISITES': ' ', 'FIELDS_OF_STUDY': ' ', 'TYPE_OF_STUDY': ' ', 'LECTURES_SEMINARS_HOMEWORK': ' 0/2/0 ', 'SYLLABUS': ' ', 'OBJECTIVES': ' The course is intended for students who are native speakers of Spanish language and seek experience in language teaching. ', 'TEXT_PREREQUISITS': ' ', 'ASSESMENT_METHODS': ' ', 'TEACHING_METHODS': ' Students will be expected to cooperate with a Language Centre teacher on preparation as well as delivery of language classes for academic or specific purposes. Each of the students will be contacted by one Language Centre teacher. The teacher will be in charge of the course and responsible for its quality. S/he will guide the student in terms of language teaching methodology. The students will team-teach with the teacher, assist him/her or otherwise enhance the quality of the sessions. The students will be expected to complete a full semester course, cooperating with one teacher. Successful students will be awarded a certificate. ', 'TEACHER_INFO': ' Los estudiantes con buenos resultados obtendrán el certificado de prácticas en enseñanza de ELE. Successful students will be awarded a certificate. ', 'LEARNING_OUTCOMES': ' ', 'LITERATURE': ' ', 'STUDENTS_ENROLLED': ' 6 ', 'STUDENTS_PASSED': ' 5 ', 'AVERAGE_GRADE': ' - ', 'FOLLOWUP_COURSES': ' '}\n"
     ]
    }
   ],
   "source": [
    "print(courses[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.helpers import edit_catalogue_for_llm, dict_print\n",
    "from scripts.embedding_helpers import embed\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# sample_courses_names = [\"IV109\", \"IV111\", \"MB152\", \"VB035\", \"PV021\", \"VV024\", \"PV168\", \"PB130\", \"PB152\", \"PB152zk\", \"PV066\", \"IB031\"]\n",
    "# sample_courses_ids = [ctoi[name] for name in sample_courses_names]\n",
    "# samples_courses = [courses[i] for i in sample_courses_ids]\n",
    "\n",
    "# for course in samples_courses:\n",
    "#     print(dict_print(edit_catalogue_for_llm(course)))\n",
    "\n",
    "# sample_embeds = [embed(client.models, dict_print(edit_catalogue_for_llm(course))).embeddings[0].values for course in samples_courses]\n",
    "\n",
    "# # Plot similarities\n",
    "\n",
    "# similarity_matrix = np.zeros((len(samples_courses), len(samples_courses)))\n",
    "# for i in range(len(samples_courses)):\n",
    "#     for j in range(len(samples_courses)):\n",
    "#         similarity_matrix[i, j] = similarity(sample_embeds[i], sample_embeds[j])\n",
    "\n",
    "# plt.imshow(similarity_matrix, interpolation='nearest', cmap='coolwarm')\n",
    "# plt.xticks(range(len(samples_courses)), sample_courses_names, rotation=45)\n",
    "# plt.yticks(range(len(samples_courses)), sample_courses_names)\n",
    "# plt.colorbar()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21106\n"
     ]
    }
   ],
   "source": [
    "all_embeds = []\n",
    "print(len(courses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# from scripts.helpers import edit_catalogue_for_llm, dict_print\n",
    "\n",
    "# for i, course in enumerate(courses):\n",
    "#     if i < 2202:\n",
    "#         continue\n",
    "#     if i % 10 == 0:\n",
    "#         print(i)\n",
    "#     time.sleep(0.15)\n",
    "#     all_embeds.append(embed(client.models, dict_print(edit_catalogue_for_llm(course))).embeddings[0].values)\n",
    "#     # if i % 100 == 0 and i != 0:\n",
    "#     #     np.save(f\"../data/embeddings/embeds{i}.npy\", all_embeds)\n",
    "\n",
    "# np.save(f\"../data/embeddings/ff.npy\", all_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(all_embeds))\n",
    "# np.save(f\"../data/embeddings/ff_.npy\", all_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fi = np.load(f\"../data/embeddings/fi.npy\", allow_pickle=True)\n",
    "# print(len(fi))\n",
    "# prf = np.load(f\"../data/embeddings/přf.npy\", allow_pickle=True)\n",
    "# print(len(prf))\n",
    "# all_embeds = np.concatenate((fi, prf), axis=0)\n",
    "\n",
    "all_embeds = np.load(f\"../data/embeddings/embeds_from_catalogue_reduced.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                        PHV444en   Complexity                                                             IA012 \n",
      " Mathematical Foundations of Computer Science                           IB000                                                                             PHV444en \n",
      " Mathematical Foundations of Computer Science                           IB000ext   Introduction to Informatics                                            IB110 \n",
      " Complexity                                                             IA012      Mathematical Foundations of Computer Science                           IB000 \n",
      " Introduction to Informatics                                            IB110      Mathematical Foundations of Computer Science                           IB000ext \n",
      " Formal Languages and Automata                                          IB005      Graph Theory                                                           M5140 \n",
      " Algorithmic game theory                                                IA168      Artificial Intelligence in Biology, Chemistry, and Bioengineering      Bi9680en \n",
      " Graph Theory                                                           M5140      Formal Languages and Automata                                          IB005 \n",
      " Computational Logic                                                    IA008      Computational Logic                                                    IA008 \n",
      " Theoretical Fundamentals of Computer Science                           E2011      Algorithmic game theory                                                IA168 \n",
      " Algorithms for Quantitative Verification                               IA175      Algorithms for Quantitative Verification                               IA175 \n",
      " Artificial Intelligence in Biology, Chemistry, and Bioengineering      Bi9680en   Mathematics IV                                                         MDA202 \n",
      " Graph Algorithms                                                       MA015      Introduction to Programming and Algorithms                             IB113 \n",
      " Mathematics IV                                                         MDA202     Machine Learning and Data Mining                                       PV056 \n",
      " Algorithmics for Hard Problems                                         IA101      Algorithmics for Hard Problems                                         IA101 \n",
      " Principles of low-level programming                                    PB111      Graph Algorithms                                                       MA015 \n",
      " Geometric Algorithms                                                   MA017      Theoretical Fundamentals of Computer Science                           E2011 \n",
      " Foundations of Programming                                             IB111      Foundations of Programming                                             IB111 \n",
      " Reinforcement Learning                                                 PA230      Principles of Programming Languages and OOP                            PB006 \n",
      " Introduction to Programming and Algorithms                             IB113      Geometric Algorithms                                                   MA017 \n"
     ]
    }
   ],
   "source": [
    "from scripts.embedding_helpers import courses_codes_to_indices, recommend_based_on_liked_disliked\n",
    "\n",
    "course_names_neg = []\n",
    "# course_names_pos = [\"PV021\", \"PV197\"]\n",
    "# course_names_neg = [\"IB111\"]\n",
    "course_names_pos = [\"MA010\", \"IA159\", \"PV021\", \"PB156\", \"IB031\", \"PB016\", \"IV109\", \"IB107\", \"PB161\"]\n",
    "course_names_neg = [\"PB007\", \"PV080\"]\n",
    "# course_names_pos = [\"PV168\"]\n",
    "# course_names_neg = [\"IB111\"]\n",
    "\n",
    "# course_names_pos = [\"PV005\", \"PV198\", \"PV157\", \"PB176\", \"PJ_03\", \"PJ_04\", \"p947\", \"IB109\", \"PV197\", \"IB031\"]\n",
    "# course_names_neg = [\"MV008\"]\n",
    "# course_names_pos = [\"PB071\", \"MB152\", \"PV021\", \"NJII_641\", \"IB002\"]\n",
    "# course_names_neg = [\"PB007\", \"PV080\", \"MB152\", \"IB000\", \"PB152cv\"]\n",
    "\n",
    "# normalize all_embeds - subtract mean and divide by std\n",
    "all_embeds_normalized = np.array(all_embeds)\n",
    "all_embeds_normalized = (all_embeds - all_embeds.mean(axis=0)) / all_embeds.std(axis=0)\n",
    "\n",
    "# Find embeds closes to 0\n",
    "# smallest_embeds = np.argsort(np.linalg.norm(all_embeds, axis=1))\n",
    "# for i in smallest_embeds[:10]:\n",
    "#     print(courses[i][\"NAME\"], courses[i][\"CODE\"])\n",
    "\n",
    "# find most similar courses\n",
    "recommended_course_indices_old, simlarities_old = recommend_based_on_liked_disliked(course_names_pos, course_names_neg, all_embeds_normalized, ctoi, 100, \"old\")\n",
    "recommended_course_indices_new, simlarities_new = recommend_based_on_liked_disliked(course_names_pos, course_names_neg, all_embeds_normalized, ctoi, 100, \"new\")\n",
    "\n",
    "# Remove courses from positive and negative lists\n",
    "recommended_course_indices_old = [i for i in recommended_course_indices_old if courses[i][\"CODE\"].strip() not in course_names_pos and courses[i][\"CODE\"].strip() not in course_names_neg]\n",
    "recommended_course_indices_new = [i for i in recommended_course_indices_new if courses[i][\"CODE\"].strip() not in course_names_pos and courses[i][\"CODE\"].strip() not in course_names_neg]\n",
    "\n",
    "for old_index, new_index in zip(recommended_course_indices_old[:20], recommended_course_indices_new[:20]):\n",
    "    print(f\"{courses[old_index]['NAME']:<70} {courses[old_index]['CODE']:<10} {courses[new_index]['NAME']:<70} {courses[new_index]['CODE']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# faculties = []\n",
    "# for course in courses:\n",
    "#     if course[\"FACULTY\"] not in faculties:\n",
    "#         faculties.append(course[\"FACULTY\"])\n",
    "\n",
    "# print(faculties)\n",
    "\n",
    "# all_embdeds = []\n",
    "# for fac in faculties:\n",
    "#     fac_embeds = np.load(f\"../data/embeddings/{fac.lower().strip()}.npy\", allow_pickle=True)\n",
    "#     all_embdeds.extend(fac_embeds)\n",
    "\n",
    "# print(len(all_embdeds))\n",
    "\n",
    "# all_embdeds = np.array(all_embdeds, dtype=np.float32)\n",
    "# np.save(f\"../data/embeddings/embeds_from_catalogue_reduced.npy\", all_embdeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Cluster all_embeds\n",
    "\n",
    "# from sklearn.cluster import KMeans\n",
    "\n",
    "# for n in range(5, 20):\n",
    "#     kmeans = KMeans(n_clusters=n, random_state=0).fit(all_embeds_normalized)\n",
    "#     print(n, kmeans.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kmeans = KMeans(n_clusters=50, random_state=0).fit(all_embeds_normalized)\n",
    "\n",
    "# for i in range(kmeans.n_clusters):\n",
    "#     # Get the course at the center of the cluster\n",
    "#     center = kmeans.cluster_centers_[i]\n",
    "#     closest = np.argmin(np.linalg.norm(all_embeds_normalized - center, axis=1))\n",
    "#     print(f\"Cluster {i}: {courses[closest]['NAME']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# for i in range(50, 700, 20):\n",
    "#     pca = PCA(n_components=i)\n",
    "#     pca.fit(all_embeds_normalized)\n",
    "#     print(i, pca.explained_variance_ratio_.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca = PCA(n_components=370)\n",
    "# pca.fit(all_embeds_normalized)\n",
    "\n",
    "# # Save the transformed data\n",
    "# all_embeds_pca = pca.transform(all_embeds_normalized)\n",
    "\n",
    "# np.save(f\"../data/embeddings/embeds_from_catalogue_reduced_pca_370.npy\", all_embeds_pca)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
